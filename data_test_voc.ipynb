{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import hashlib\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import copy\n",
    "import shutil\n",
    "import time\n",
    "from itertools import repeat\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from pathlib import Path\n",
    "from scipy import ndimage\n",
    "import cv2\n",
    "import logging\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from PIL import ExifTags, Image, ImageOps, ImageDraw, ImageFont\n",
    "from torch.utils.data import DataLoader, Dataset, dataloader, distributed\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "from typing import Dict, Any\n",
    "import collections\n",
    "import transforms as T\n",
    "from tool.utils import *\n",
    "from engine import train_one_epoch, evaluate\n",
    "from metric import *\n",
    "\n",
    "\"\"\"\n",
    "    data util\n",
    "\"\"\"\n",
    "class load_voc():\n",
    "    def __init__(self, root_dir, set_name='VOC2007_test'):\n",
    "        self.root_dir = root_dir\n",
    "        self.set_name = set_name\n",
    "        \n",
    "        self.classes = [\n",
    "                        \"aeroplane\",\n",
    "                        \"bicycle\",\n",
    "                        \"bird\",\n",
    "                        \"boat\",\n",
    "                        \"bottle\",\n",
    "                        \"bus\",\n",
    "                        \"car\",\n",
    "                        \"cat\",\n",
    "                        \"chair\",\n",
    "                        \"cow\",\n",
    "                        \"diningtable\",\n",
    "                        \"dog\",\n",
    "                        \"horse\",\n",
    "                        \"motorbike\",\n",
    "                        \"person\",\n",
    "                        \"pottedplant\",\n",
    "                        \"sheep\",\n",
    "                        \"sofa\",\n",
    "                        \"train\",\n",
    "                        \"tvmonitor\"\n",
    "                    ]\n",
    "        \n",
    "        # preparing a data list\n",
    "        #dataset = 'VOC2007' # or VOC2007_test, VOC2012, VOC2007+2012\n",
    "        #path = '/nasdata2/khj/objectdetection/segmentation/VOCdevkit/'\n",
    "        if self.set_name in ['VOC2007', 'VOC2007_test', 'VOC2012']:\n",
    "\n",
    "            img_base_path = os.path.join(self.root_dir,self.set_name,'JPEGImages')\n",
    "\n",
    "            self.img_files = glob.glob(os.path.join(img_base_path,'*.jpg'))\n",
    "            self.label_files = [ i.replace('JPEGImages','Annotations').replace('jpg','xml') for i in self.img_files ]\n",
    "\n",
    "        elif self.set_name == 'VOC2007+2012':\n",
    "\n",
    "            img_base_path_2007, img_base_path_2012 = os.path.join(self.root_dir,'VOC2007','JPEGImages'), os.path.join(self.root_dir,'VOC2012','JPEGImages')\n",
    "\n",
    "            img_files_2007, img_files_2012 = glob.glob(os.path.join(img_base_path_2007,'*.jpg')), glob.glob(os.path.join(img_base_path_2012,'*.jpg'))\n",
    "            label_files_2007 = [ i.replace('JPEGImages','Annotations').replace('jpg','xml') for i in img_files_2007 ]\n",
    "            label_files_2012 = [ i.replace('JPEGImages','Annotations').replace('jpg','xml') for i in img_files_2012 ]\n",
    "\n",
    "            self.img_files, self.label_files = img_files_2007 + img_files_2012, label_files_2007 + label_files_2012\n",
    "\n",
    "    def parse_voc_xml(self, node: ET.Element) -> Dict[str, Any]: # xml 파일을 dictionary로 반환\n",
    "        voc_dict: Dict[str, Any] = {}\n",
    "        children = list(node)\n",
    "        if children:\n",
    "            def_dic: Dict[str, Any] = collections.defaultdict(list)\n",
    "            for dc in map(self.parse_voc_xml, children):\n",
    "                for ind, v in dc.items():\n",
    "                    def_dic[ind].append(v)\n",
    "            if node.tag == \"annotation\":\n",
    "                def_dic[\"object\"] = [def_dic[\"object\"]]\n",
    "            voc_dict = {node.tag: {ind: v[0] if len(v) == 1 else v for ind, v in def_dic.items()}}\n",
    "        if node.text:\n",
    "            text = node.text.strip()\n",
    "            if not children:\n",
    "                voc_dict[node.tag] = text\n",
    "        return voc_dict\n",
    "    \n",
    "    def get_annotations(self,annot_file):\n",
    "        target = self.parse_voc_xml(ET.parse(annot_file).getroot())\n",
    "        annotations = np.zeros((0, 5))\n",
    "        \n",
    "        for t in target['annotation']['object']:\n",
    "            annotation = np.zeros((1, 5))\n",
    "            annotation[0, 1:] = np.array( [ t['bndbox']['xmin'], t['bndbox']['ymin'], t['bndbox']['xmax'], t['bndbox']['ymax'] ] )\n",
    "            annotation[0, 0] = self.classes.index(t['name'])\n",
    "            annotations = np.append(annotations, annotation, axis=0)\n",
    "        \n",
    "        return annotations\n",
    "\n",
    "    def get_dataset(self):\n",
    "        \n",
    "        print('We found {} files... Read images/labels...'.format(len(self.img_files)))\n",
    "        cnt = 0\n",
    "        since = time.time()\n",
    "        img_all, label_all = [], []\n",
    "        for idx in range(len(self.img_files)):\n",
    "            if cnt % 1000 == 0 and cnt != 0: \n",
    "                time_elapsed = time.time() - since\n",
    "                print('\\t Current idx {}... complete in {:.0f}m {:.0f}s'.format(cnt, time_elapsed // 60, time_elapsed % 60))\n",
    "            img_all.append(np.array(Image.open(self.img_files[idx]).convert('RGB')))\n",
    "            label_all.append(self.get_annotations(self.label_files[idx]))\n",
    "            cnt += 1\n",
    "            \n",
    "        return img_all, label_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_loader = load_voc(root_dir='/nasdata2/khj/objectdetection/segmentation/VOCdevkit/', set_name='VOC2007_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We found 4952 files... Read images/labels...\n",
      "\t Current idx 1000... complete in 0m 6s\n",
      "\t Current idx 2000... complete in 0m 12s\n",
      "\t Current idx 3000... complete in 0m 18s\n",
      "\t Current idx 4000... complete in 0m 25s\n"
     ]
    }
   ],
   "source": [
    "img_all, label_all = voc_loader.get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4952\n",
      "(500, 353, 3)\n",
      "[[ 11.  48. 240. 195. 371.]\n",
      " [ 14.   8.  12. 352. 498.]]\n"
     ]
    }
   ],
   "source": [
    "print(len(img_all))\n",
    "print(np.shape(img_all[0]))\n",
    "\n",
    "print(label_all[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "foryolo",
   "language": "python",
   "name": "foryolo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
